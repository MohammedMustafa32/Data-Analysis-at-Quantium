# -*- coding: utf-8 -*-
'''Quantium Task 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kEmcswYGizUDeVOLQpo2SriNaZ8WOIaQ
'''

# Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind
import datetime
from scipy.stats import t

#path = 'myDrive/MyDrive/Dataset/'
path = 'C:\\Users\\Mohammed Nawar\\Downloads\\Quantium ( Data Analysis )\\Quantium - Task 2\\'


data = pd.read_csv(path+'QVI_data.csv')

data['DATE'] = pd.to_datetime(data['DATE']).astype(str)

data['MONTH_ID'] = data['DATE'].str[:7]
data['MONTH_ID'] = data['MONTH_ID'].apply(lambda x: x.replace('-', '')).astype(int)
print(data[['DATE', 'MONTH_ID']].head())


measureOverTime = data.groupby(['STORE_NBR', 'MONTH_ID']).agg({
                                                                'TOT_SALES': 'sum',               # total salse
                                                                'LYLTY_CARD_NBR': 'nunique',      # number of customer (unique)
                                                                'TXN_ID': 'count',                # number of transections
                                                                'PROD_QTY': 'sum'                 # total quantity
                                                              }).reset_index()

measureOverTime.rename(columns={'LYLTY_CARD_NBR': 'Customers_ID',
                                'TXN_ID': 'Transections_ID'}, inplace=True)

# number of transactions per customer
measureOverTime['Transections_Per_Customer'] = measureOverTime['Transections_ID'] / measureOverTime['Customers_ID']
# number of chips per customer
measureOverTime['Chips_Per_Customer'] = measureOverTime['PROD_QTY'] / measureOverTime['Customers_ID']
# average price per unit
measureOverTime['AVG_Price_Per_Unit'] = measureOverTime['TOT_SALES'] / measureOverTime['PROD_QTY']


# sort by (store and month)
measureOverTime = measureOverTime.sort_values(by=['STORE_NBR', 'MONTH_ID'])

print(measureOverTime.head(10))

# Select stores with 12 months of data
store_month_counts = measureOverTime.groupby('STORE_NBR')['MONTH_ID'].nunique()
stores_with_full_obs = store_month_counts[store_month_counts == 12].index

# Filter for pre-trial period (before Feb 2019)
pre_trial_measures = measureOverTime[(measureOverTime['MONTH_ID'] < 201902) & (measureOverTime['STORE_NBR'].isin(stores_with_full_obs))]

print(pre_trial_measures.head(10))

# Define function to calculate Pearson correlation between trial and control stores
def calculate_correlation(input_table, metric_col, trial_store):
    trial_data = input_table[input_table['STORE_NBR'] == trial_store][['MONTH_ID', metric_col]].set_index('MONTH_ID')

    results = []
    for control_store in input_table['STORE_NBR'].unique():
        if control_store == trial_store:
            continue
        control_data = input_table[input_table['STORE_NBR'] == control_store][['MONTH_ID', metric_col]].set_index('MONTH_ID')
        merged_data = trial_data.join(control_data, lsuffix='_trial', rsuffix='_control').dropna()
        correlation = merged_data.corr().iloc[0, 1] if not merged_data.empty else 0
        results.append({'Trial_Store': trial_store, 'Control_Store': control_store, 'Correlation': correlation})

    return pd.DataFrame(results)

# Define function to calculate magnitude distance
def calculate_magnitude_distance(input_table, metric_col, trial_store):
    trial_data = input_table[input_table['STORE_NBR'] == trial_store][['MONTH_ID', metric_col]]
    results = []

    for control_store in input_table['STORE_NBR'].unique():
        if control_store == trial_store:
            continue
        control_data = input_table[input_table['STORE_NBR'] == control_store][['MONTH_ID', metric_col]]
        merged_data = trial_data.merge(control_data, on='MONTH_ID', suffixes=('_trial', '_control'))
        merged_data['measure'] = np.abs(merged_data[f'{metric_col}_trial'] - merged_data[f'{metric_col}_control'])
        min_dist, max_dist = merged_data['measure'].min(), merged_data['measure'].max()
        merged_data['magnitude_measure'] = 1 - ((merged_data['measure'] - min_dist) / (max_dist - min_dist)) if max_dist > min_dist else 1
        avg_magnitude = merged_data['magnitude_measure'].mean()

        results.append({'Trial_Store': trial_store, 'Control_Store': control_store, 'Magnitude_Distance': avg_magnitude})

    return pd.DataFrame(results)

def Model(trial_store):
  corr_nSales = calculate_correlation(pre_trial_measures, 'TOT_SALES', trial_store)
  corr_nCustomers = calculate_correlation(pre_trial_measures, 'Customers_ID', trial_store)

  mag_nSales = calculate_magnitude_distance(pre_trial_measures, 'TOT_SALES', trial_store)
  mag_nCustomers = calculate_magnitude_distance(pre_trial_measures, 'Customers_ID', trial_store)

  print("ðŸ”¹ Top stores based on correlation coefficient in total sales: ")
  print(corr_nSales.sort_values(by='Correlation', ascending=False).head())

  print("\nðŸ”¹ Best stores based on customer correlation: ")
  print(corr_nCustomers.sort_values(by='Correlation', ascending=False).head())

  print("\nðŸ”¹ Top Stores Based on Standard Distance in Total Sales: ")
  print(mag_nSales.sort_values(by='Magnitude_Distance', ascending=False).head())

  print("\nðŸ”¹ Best stores based on standard distance in number of customers: ")
  print(mag_nCustomers.sort_values(by='Magnitude_Distance', ascending=False).head())

  # Specify the weight of the correlation coefficient
  corr_weight = 0.5

  # combined score composed of correlation and magnitude
  score_nSales = pd.merge(corr_nSales, mag_nSales, on=['Trial_Store', 'Control_Store'])
  score_nCustomers = pd.merge(corr_nCustomers, mag_nCustomers, on=['Trial_Store', 'Control_Store'])


  score_nSales['Composite_Score_Sales'] = (corr_weight * score_nSales['Correlation']) + ((1 - corr_weight) * score_nSales['Magnitude_Distance'])
  score_nCustomers['Composite_Score_Customers'] = (corr_weight * score_nCustomers['Correlation']) + ((1 - corr_weight) * score_nCustomers['Magnitude_Distance'])

  print("ðŸ”¹ Top stores based on composite measure of total sales: ")
  print(score_nSales.sort_values(by='Composite_Score_Sales', ascending=False).head())

  print("\nðŸ”¹ Top stores based on composite customer count: ")
  print(score_nCustomers.sort_values(by='Composite_Score_Customers', ascending=False).head())


  # Combine scores across the drivers by first merging our sales scores and customer scores into a single table
  score_Control = pd.merge(score_nSales, score_nCustomers, on=['Trial_Store', 'Control_Store'])

  score_Control['Final_Control_Score'] = (score_Control['Composite_Score_Sales'] * 0.5) + (score_Control['Composite_Score_Customers'] * 0.5)

  # Sort control stores based on final score and choose the best one
  best_control_stores = score_Control.sort_values(by='Final_Control_Score', ascending=False)

  # The store with the highest score is then selected as the control store since it is most similar to the trial store.
  print("ðŸ”¹ Best Control Stores Based on Final Score: ")
  print(best_control_stores.head())

  selected_control_store = best_control_stores.iloc[0]['Control_Store']
  print('#######################################################################')
  print(f"ðŸ”¹ The selected control store for the trial store {trial_store} is: {selected_control_store}")
  print('#######################################################################')


  ##########################################

  control_store = selected_control_store  #
  measureOverTimeSales = measureOverTime.copy()

  pre_trial_sales = measureOverTimeSales[measureOverTimeSales['MONTH_ID'] < 201903].copy()
  pre_trial_sales['Store_Type'] = pre_trial_sales['STORE_NBR'].apply(
      lambda x: 'Trial' if x == trial_store else ('Control' if x == control_store else 'Other Stores')
    )

  # -> Total Sales
  # Calculate average monthly sales for each category
  # Visual checks on trends based on the drivers
  pastSales = pre_trial_sales.groupby(['MONTH_ID', 'Store_Type'])['TOT_SALES'].mean().reset_index()
  pastSales['TransactionMonth'] = pd.to_datetime(pastSales['MONTH_ID'], format='%Y%m')

  plt.figure(figsize=(12, 6))
  sns.lineplot(data=pastSales, x='TransactionMonth', y='TOT_SALES', hue='Store_Type', marker='o')
  plt.xlabel("Month of Operation")
  plt.ylabel("Total Sales")
  plt.title("Total Sales by Month")
  plt.legend(title="Type of Store")
  plt.grid(True)
  plt.show()



  # -> Number of Customers
  #visual checks on customer count trends by comparing the trial store to the control store and other stores.
  pastCustomers = pre_trial_sales.groupby(['MONTH_ID', 'Store_Type'])['Customers_ID'].mean().reset_index()
  pastCustomers['TransactionMonth'] = pd.to_datetime(pastCustomers['MONTH_ID'], format='%Y%m')

  plt.figure(figsize=(12, 6))
  sns.lineplot(data=pastCustomers, x='TransactionMonth', y='Customers_ID', hue='Store_Type', marker='o')
  plt.xlabel("Month of operation")
  plt.ylabel("Number of Customers")
  plt.title("Number of Customers by Month")
  plt.legend(title="Type of Store")
  plt.grid(True)
  plt.show()



  #######################################################

  # For Total Sales

  control_store = selected_control_store

  # Scaling control store sales to match pre-trial trial store sales
  scalingFactorForControlSales = pre_trial_measures[pre_trial_measures['STORE_NBR'] == trial_store]['TOT_SALES'].sum() / \
                  pre_trial_measures[pre_trial_measures['STORE_NBR'] == selected_control_store]['TOT_SALES'].sum()

  print(f"Scaling Factor for Control Sales: {scalingFactorForControlSales}")


  # Apply the scaling factor
  measureOverTimeSales = measureOverTime.copy()
  measureOverTimeSales.loc[measureOverTimeSales['STORE_NBR'] == control_store, 'controlSales'] = measureOverTimeSales.loc[measureOverTimeSales['STORE_NBR'] == control_store, 'TOT_SALES'] * scalingFactorForControlSales
  measureOverTimeSales['Store_type'] = measureOverTimeSales['STORE_NBR'].apply(
      lambda x: 'Trial' if x == trial_store else ('Control' if x == control_store else 'Other stores')
  )


  # Extract sales data for the ( Trial Store ) during the trial period
  # [ Trial period: February 2019 to April 2019 ]
  trial_period = (measureOverTimeSales['MONTH_ID'] >= 201902) & (measureOverTimeSales['MONTH_ID'] <= 201904)

  trial_cust = measureOverTimeSales[(measureOverTimeSales['STORE_NBR'] == trial_store) & trial_period][['MONTH_ID', 'TOT_SALES']]
  control_cust = measureOverTimeSales[(measureOverTimeSales['STORE_NBR'] == control_store) & trial_period][['MONTH_ID', 'controlSales']]

  percentageDiff_Sales = pd.merge(trial_cust, control_cust, on='MONTH_ID', how='inner')
  percentageDiff_Sales['percentageDiff'] = np.abs(percentageDiff_Sales['controlSales'] - percentageDiff_Sales['TOT_SALES']) / percentageDiff_Sales['controlSales'] * 100

  print("\nMerged Customer Data with Percentage Difference during Trial Period:")
  print(percentageDiff_Sales)


  # Calculate the standard deviation of the relative difference in the pre-trial period.
  stdDev = percentageDiff_Sales['percentageDiff'].std()

  # Note that there are 8 months in the pre-trial period
  # hence 8 - 1 = 7 degrees of freedom
  degreesOfFreedom = 7

  print("Standard Deviation of percentage difference (pre-trial):", stdDev)
  print("Degrees of Freedom:", degreesOfFreedom)


  # Calculate the t-values for the trial months
  #### to check whether the hypothesis is statistically significant.
  #### Hint: The test statistic here is (x - u)/standard deviation
  percentageDiff_Sales['tValue'] = (percentageDiff_Sales['percentageDiff']) / stdDev
  percentageDiff_Sales['TransactionMonth'] = pd.to_datetime(percentageDiff_Sales['MONTH_ID'], format='%Y%m')
  print("ðŸ”¹ Results T-test:")
  print(percentageDiff_Sales[['TransactionMonth', 'percentageDiff', 'tValue']])

  t_critical = t.ppf(0.95, df=degreesOfFreedom)
  print(f"\nðŸ”¹ the 95% of the t-distribution: {t_critical}")



  pastSales = measureOverTimeSales[measureOverTimeSales['Store_type'].isin(['Trial', 'Control'])].groupby(['MONTH_ID', 'Store_type'])['TOT_SALES'].mean().reset_index()
  pastSales['TransactionMonth'] = pd.to_datetime(pastSales['MONTH_ID'], format='%Y%m')

  control_sales = pastSales[pastSales['Store_type'] == 'Control'].copy()
  control_sales['Upper'] = control_sales['TOT_SALES'] * (1 + stdDev * 2)
  control_sales['Lower'] = control_sales['TOT_SALES'] * (1 - stdDev * 2)

  trialAssessment_sales = pd.concat([
      pastSales,
      control_sales[['MONTH_ID', 'Upper']].rename(columns={'Upper':'TOT_SALES'}).assign(Store_type='Control 95th % confidence interval'),
      control_sales[['MONTH_ID', 'Lower']].rename(columns={'Lower':'TOT_SALES'}).assign(Store_type='Control 5th % confidence interval')
  ], ignore_index=True)

  trialAssessment_sales['TransactionMonth'] = pd.to_datetime(trialAssessment_sales['MONTH_ID'], format='%Y%m')


  plt.figure(figsize=(12, 6))
  sns.lineplot(data=trialAssessment_sales, x='TransactionMonth', y='TOT_SALES', hue='Store_type', marker='o')
  plt.xlabel("Month of Operation")
  plt.ylabel("Number of Sales")
  plt.title("Number of Sales by Month")
  plt.axvspan(pd.to_datetime("2019-02-01"), pd.to_datetime("2019-04-30"), color='grey', alpha=0.3, label="Trial Period")
  plt.legend(title="Store Type")
  plt.grid(True)
  plt.show()



  ##############################

  # For Number of Customer
  # calculate Scaling Factor
  pre_trial = measureOverTime[measureOverTime['MONTH_ID'] < 201902]

  trial_customers_sum = pre_trial[pre_trial['STORE_NBR'] == trial_store]['Customers_ID'].sum()
  control_customers_sum = pre_trial[pre_trial['STORE_NBR'] == control_store]['Customers_ID'].sum()

  scalingFactorForControlCust = trial_customers_sum / control_customers_sum
  print("Scaling Factor for Control Customers:", scalingFactorForControlCust)

  # Apply the scaling factor
  measureOverTimeCusts = measureOverTime.copy()
  measureOverTimeCusts.loc[measureOverTimeCusts['STORE_NBR'] == control_store, 'controlCustomers'] = measureOverTimeCusts.loc[measureOverTimeCusts['STORE_NBR'] == control_store, 'Customers_ID'] * scalingFactorForControlCust
  measureOverTimeCusts['Store_type'] = measureOverTimeCusts['STORE_NBR'].apply(
      lambda x: 'Trial' if x == trial_store else ('Control' if x == control_store else 'Other stores')
  )

  # Extract modified CUSTOMERS data for the ( Control Store ) during the trial period
  # [ Trial period: February 2019 to April 2019 ]
  trial_period = (measureOverTimeCusts['MONTH_ID'] >= 201902) & (measureOverTimeCusts['MONTH_ID'] <= 201904)

  trial_cust = measureOverTimeCusts[(measureOverTimeCusts['STORE_NBR'] == trial_store) & trial_period][['MONTH_ID', 'Customers_ID']]
  control_cust = measureOverTimeCusts[(measureOverTimeCusts['STORE_NBR'] == control_store) & trial_period][['MONTH_ID', 'controlCustomers']]

  percentageDiff_customers = pd.merge(trial_cust, control_cust, on='MONTH_ID', how='inner')
  percentageDiff_customers['percentageDiff'] = np.abs(percentageDiff_customers['controlCustomers'] - percentageDiff_customers['Customers_ID']) / percentageDiff_customers['controlCustomers'] * 100

  print("\nMerged Customer Data with Percentage Difference during Trial Period:")
  print(percentageDiff_customers)


  # -------------------------------
  trial_cust_pre = pre_trial[pre_trial['STORE_NBR'] == trial_store][['MONTH_ID', 'Customers_ID']]
  control_cust_pre = pre_trial[pre_trial['STORE_NBR'] == control_store][['MONTH_ID', 'Customers_ID']]

  control_cust_pre = control_cust_pre.copy()
  control_cust_pre['controlCustomers'] = control_cust_pre['Customers_ID'] * scalingFactorForControlCust

  merged_customers_pre = pd.merge(trial_cust_pre, control_cust_pre[['MONTH_ID', 'controlCustomers']], on='MONTH_ID', how='inner')
  merged_customers_pre['percentageDiff'] = np.abs(merged_customers_pre['controlCustomers'] - merged_customers_pre['Customers_ID']) / merged_customers_pre['controlCustomers'] * 100

  stdDev_customers = merged_customers_pre['percentageDiff'].std()
  degreesOfFreedom = 7

  print("\nStandard Deviation of percentage differences (pre-trial) for Customers:", stdDev_customers)
  print("Degrees of Freedom:", degreesOfFreedom)

  # Calculate the average number of customers per month for each category (Trial and Control) during the pre-trial period
  pastCustomers = measureOverTimeCusts[measureOverTimeCusts['Store_type'].isin(['Trial', 'Control'])].groupby(['MONTH_ID', 'Store_type'])['Customers_ID'].mean().reset_index()
  pastCustomers['TransactionMonth'] = pd.to_datetime(pastCustomers['MONTH_ID'], format='%Y%m')

  control_customers = pastCustomers[pastCustomers['Store_type'] == 'Control'].copy()
  control_customers['Upper'] = control_customers['Customers_ID'] * (1 + stdDev_customers * 2)
  control_customers['Lower'] = control_customers['Customers_ID'] * (1 - stdDev_customers * 2)

  trialAssessment_customers = pd.concat([
      pastCustomers,
      control_customers[['MONTH_ID', 'Upper']].rename(columns={'Upper':'Customers_ID'}).assign(Store_type='Control 95th % confidence interval'),
      control_customers[['MONTH_ID', 'Lower']].rename(columns={'Lower':'Customers_ID'}).assign(Store_type='Control 5th % confidence interval')
  ], ignore_index=True)

  trialAssessment_customers['TransactionMonth'] = pd.to_datetime(trialAssessment_customers['MONTH_ID'], format='%Y%m')

  plt.figure(figsize=(12, 6))
  sns.lineplot(data=trialAssessment_customers, x='TransactionMonth', y='Customers_ID', hue='Store_type', marker='o')
  plt.xlabel("Month of Operation")
  plt.ylabel("Number of Customers")
  plt.title("Number of Customers by Month")
  plt.axvspan(pd.to_datetime("2019-02-01"), pd.to_datetime("2019-04-30"), color='grey', alpha=0.3, label="Trial Period")
  plt.legend(title="Store Type")
  plt.grid(True)
  plt.show()

# @title 1- Select Trial Store (77)
Model(77)

# @title 2- Select Trial Store (86)
Model(86)

## @title 3- Select Trial Store (88)
Model(88)

